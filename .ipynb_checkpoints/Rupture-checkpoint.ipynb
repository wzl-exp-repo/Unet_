{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ODNLPGHKKgr-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import glob\n",
    "#import zipfile\n",
    "#import functools\n",
    "\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from itertools import combinations\n",
    "#import matplotlib.image as mpimg\n",
    "#import pandas as pd\n",
    "#from PIL import Image\n",
    "#import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YQ9VRReUQxXi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.contrib as tfcontrib\n",
    "#from tensorflow.python.keras import layers\n",
    "#from tensorflow.python.keras import losses\n",
    "#from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import backend as K\n",
    "#from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Segmentation.solver import Solver\n",
    "from Segmentation.architecture.unet import Unet\n",
    "from Segmentation.preprocess import Data_Preprocess\n",
    "from Segmentation.assistant import assistant\n",
    "import Segmentation.vis_utils as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "dataset_path = os.path.join( dirname , \"DATA/dataset\")\n",
    "train_path = os.path.join(dataset_path , \"training\")\n",
    "test_path = os.path.join( dataset_path , \"testing\")\n",
    "csv_path = os.path.join( dataset_path , \"train.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Data_Preprocess(dataset_path = dataset_path\n",
    "                       ,train_path = train_path\n",
    "                       ,test_path = test_path\n",
    "                       ,image_shape = (64, 64, 3)\n",
    "                       ,batch_size = 1\n",
    "                       ,csv_path = csv_path\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filenames, x_val_filenames, y_train_filenames, y_val_filenames = test.get_train_val_split_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhvDoZkbcUa1"
   },
   "source": [
    "# Visualize\n",
    "Let's take a look at some of the examples of different images in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.visualize_pairs(x_train_filenames,y_train_filenames,num = 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4CPgvPiToB_"
   },
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfeMRgyoa2n6"
   },
   "source": [
    "Let’s begin by setting up some parameters. We’ll standardize and resize all the shapes of the images. We’ll also set up some training parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oeDoiSFlothe"
   },
   "outputs": [],
   "source": [
    "img_shape = (64, 64, 3)  #(256, 256, 3)\n",
    "batch_size = 10 #3\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_HONB9JbXxDM"
   },
   "source": [
    "# Build our input pipeline with `tf.data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwtgius5CRKc"
   },
   "source": [
    "## Set up train and validation datasets\n",
    "Note that we apply image augmentation to our training dataset but not our validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iu5WmYmOwKrV"
   },
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1 / 255.,\n",
    "    'hue_delta': 0.1,\n",
    "    'horizontal_flip': True,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(test._augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RtzLkDFMpF0T"
   },
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1 / 255.,\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(test._augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5cNpECdkaafo"
   },
   "outputs": [],
   "source": [
    "train_ds = test.get_baseline_dataset(x_train_filenames,\n",
    "                                     y_train_filenames,\n",
    "                                     preproc_fn=tr_preprocessing_fn,\n",
    "                                    )\n",
    "val_ds = test.get_baseline_dataset(x_val_filenames,\n",
    "                                   y_val_filenames, \n",
    "                                   preproc_fn=val_preprocessing_fn,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yasuvr5IbFlM"
   },
   "source": [
    "## Let's see if our image augmentor data pipeline is producing expected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjoUqbPdHQej"
   },
   "outputs": [],
   "source": [
    "temp_ds = test.get_baseline_dataset(x_train_filenames, \n",
    "                               y_train_filenames,\n",
    "                               preproc_fn=tr_preprocessing_fn,\n",
    "                               shuffle=False)\n",
    "# Let's examine some of these augmented images\n",
    "data_aug_iter = temp_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "with tf.Session() as sess: \n",
    "  batch_of_imgs, label = sess.run(next_element)\n",
    "\n",
    "  # Running next element in our graph will produce a batch of images\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  img = batch_of_imgs[0]\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(img)\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  #plt.imshow(label[0, :, :, 0])\n",
    "  plt.imshow(label[0, :, :, 0])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvtxCncKsoRd"
   },
   "source": [
    "# Build the model\n",
    "\n",
    "## The Keras Functional API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WG_8iZ_dMbK"
   },
   "source": [
    "## Train your model\n",
    "Training your model with `tf.data` involves simply providing the model's `fit` function with your training/validation dataset, the number of steps, and epochs.  \n",
    "\n",
    "We also include a Model callback, [`ModelCheckpoint`](https://keras.io/callbacks/#modelcheckpoint) that will save the model to disk after each epoch. We configure it such that it only saves our highest performing model. Note that saving the model capture more than just the weights of the model: by default, it saves the model architecture, weights, as well as information about the training process such as the state of the optimizer, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train_examples = len(x_train_filenames)\n",
    "num_val_examples = len(x_val_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = {\n",
    "                    'lr': 1e-5,\n",
    "                    'decay': 0.9,\n",
    "                    'rho': 0.9,\n",
    "                    'epsilon': 1e-10\n",
    "                }\n",
    "params = {  'num_train_examples' : num_train_examples\n",
    "            ,'num_val_examples' : num_val_examples\n",
    "            ,'batch_size' : batch_size\n",
    "            ,'num_epochs' : epochs\n",
    "            ,'loss' : 'bce_dice_loss'\n",
    "            ,'optimizer' : 'rms'\n",
    "            ,'optimizer_config' : optim_config\n",
    "            ,'metrics' : ['dice_loss','f1','recall','precision']\n",
    "            ,'save_model_path' : os.path.join(os.getcwd(),'weights.hdf5')\n",
    "            ,'verbose' : True\n",
    "         }\n",
    "history = assis.run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old version of training. Don't use encoder decoder spliter\n",
    "\n",
    "model = Unet()\n",
    "#model.build_model()\n",
    "\n",
    "optim_config = {\n",
    "                    'lr': 1e-5,\n",
    "                    'decay': 0.9,\n",
    "                    'rho': 0.9,\n",
    "                    'epsilon': 1e-10\n",
    "                }\n",
    "\n",
    "solver = Solver(model.build_model()\n",
    "                ,train_ds, val_ds\n",
    "                ,num_train_examples = num_train_examples\n",
    "                ,num_val_examples = num_val_examples\n",
    "                ,batch_size = 2\n",
    "                ,num_epochs = epochs\n",
    "                ,loss = 'bce_dice_loss'\n",
    "                ,optimizer = 'rms'\n",
    "                ,optimizer_config = optim_config\n",
    "                ,metrics = ['dice_loss','f1','recall','precision']\n",
    "                ,save_model_path = os.path.join(os.getcwd(),'weights.hdf5')\n",
    "                ,verbose = True\n",
    "               )\n",
    "history = solver.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCAUsoxfTTrh"
   },
   "source": [
    "# Visualize training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvntxymYn8rM"
   },
   "outputs": [],
   "source": [
    "train_dice = history.history['dice_loss']\n",
    "val_dice = history.history['val_dice_loss']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_dice, label='Training Dice Loss')\n",
    "plt.plot(epochs_range, val_dice, label='Validation Dice Loss')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Dice Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall = history.history['recall']\n",
    "val_recall   = history.history['val_recall']\n",
    "\n",
    "train_precision = history.history['precision']\n",
    "val_precision   = history.history['val_precision']\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_precision, label='Training Precision')\n",
    "plt.plot(epochs_range, val_precision, label='Validation Precision')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Precisions')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_recall, label='Training Recall')\n",
    "plt.plot(epochs_range, val_recall, label='Validation Recall')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Recall')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = history.history['F1']\n",
    "val_f1   = history.history['val_F1']\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(epochs_range, train_f1, label='Training F1 score')\n",
    "plt.plot(epochs_range, val_f1, label='Validation F1 score')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.title('Training and Validation F1 scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGFKf8yCTYbw"
   },
   "source": [
    "# Visualize actual performance \n",
    "We'll visualize our performance on the validation set.\n",
    "\n",
    "Note that in an actual setting (competition, deployment, etc.) we'd evaluate on the test set with the full image resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_recover = models.load_model(assis.weights_path, custom_objects={'bce_dice_loss': assis.decoder.bce_dice_loss\n",
    "                                                              ,'dice_loss': assis.solver.dice_loss\n",
    "                                                              ,'precision' : assis.solver.precision\n",
    "                                                              ,'recall' : assis.solver.recall\n",
    "                                                              ,'F1' : assis.solver.F1\n",
    "                                                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assis.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GnwZ7CPaamI"
   },
   "outputs": [],
   "source": [
    "# Let's visualize some of the outputs \n",
    "vis.visualize_result_triples(assis,assis.weights_path,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Segmentation",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
